{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%run test_functions.ipynb\n",
    "\n",
    "#Todo\n",
    "\"\"\"\n",
    "1. We need to fix this code after changing K_test function on test_functions.py\n",
    "2. Change x-axis of K_test plot to computation time.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Plot 3: Testing convergence on different K value\n",
    "\n",
    "Here we run for fixed T_cap, However we use optimal step-size for each case with very low epsilon 1e-8, so as to not\n",
    "terminate before T_cap. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "current_path = os.getcwd()\n",
    "parent_path = os.path.dirname(current_path)\n",
    "\n",
    "\n",
    "# T = 100000 #Number of Total Iteration\n",
    "J_sst = 10  # Number of Cohorts\n",
    "L_sst = 25  # Number of Treatments\n",
    "\n",
    "\n",
    "dual_gap_freq_sst = 10\n",
    "n_sst = 10000\n",
    "K_list_sst = [10,30,50,75,100,150,200]  # 6 Instance\n",
    "T_cap_sst = 10000\n",
    "print_opt = 1\n",
    "\n",
    "repeats_sst = 50  # Currently we don't take average here\n",
    "m_sst = 5\n",
    "\n",
    "# stat_list_sst[n_idx][rep_idx][alg_idx]\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for rep_idx in range(repeats_sst):\n",
    "    stat_list = K_test_iter(J_sst, L_sst, dual_gap_freq_sst, n_sst, K_list_sst, T_cap_sst,\n",
    "                                m_sst, print_opt)\n",
    "    result_list.append(stat_list)\n",
    "\n",
    "#Save this data into csv form\n",
    "\n",
    "#Get the length of each dual_gap_list\n",
    "dual_len = len(result_list[0][0].dual_gap_list[0])\n",
    "dual_gap_arr = np.zeros((repeats_sst,len(K_list_sst)+1, dual_len))\n",
    "\n",
    "for rep_idx in range(repeats_sst):\n",
    "    for k_idx in range(len(K_list_sst)+1):\n",
    "        dual_gap_arr[rep_idx,k_idx,:] = result_list[rep_idx][k_idx].dual_gap_list[0]\n",
    "\n",
    "avg_dual_gap = np.average(dual_gap_arr,axis = 0)\n",
    "\n",
    "#Save in csv\n",
    "\n",
    "data_list = []\n",
    "for k_idx in range(len(K_list_sst)):\n",
    "    temp_list = [n_sst, J_sst * L_sst, m_sst,K_list_sst[k_idx], T_cap_sst, dual_gap_freq_sst]\n",
    "    temp_list.append(avg_dual_gap[k_idx,:].tolist())\n",
    "    data_list.append(temp_list)\n",
    "temp_list = [n_sst, J_sst * L_sst, m_sst,'FMD', T_cap_sst, dual_gap_freq_sst]\n",
    "temp_list.append(avg_dual_gap[len(K_list_sst),:].tolist())\n",
    "data_list.append(temp_list)\n",
    "\n",
    "df= pd.DataFrame(data_list, columns = ['n','d','m','K','Total_Iter', 'Dual_Freq', 'Avg_Dual_Gap'])\n",
    "save_path = parent_path + '/results/K_test0_n=' +str(n_sst) + 'd=' + str(J_sst * L_sst) + '_m=' + str(m_sst) + '.csv'\n",
    "df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# i_flag_count_list = []\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     temp_list = []\n",
    "#     for alg_idx in range(len(alg_list_sst)):\n",
    "#         temp = np.zeros(repeats_sst)\n",
    "#         for rep_idx in range(repeats_sst):  # repeats_sst == 1 code\n",
    "#             temp[rep_idx] = stat_list_sst[n_idx][rep_idx][alg_idx].i_flag_count\n",
    "#         temp_list.append(np.mean(temp))\n",
    "#     i_flag_count_list.append(temp_list)\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     print('i flag count when n = %s' % n_list_sst[n_idx])\n",
    "#     for k_idx, value in enumerate(i_flag_count_list[n_idx]):\n",
    "#         print('K value: %s, i_flag_count: %s ' % (K_list_sst[k_idx], value))\n",
    "#\n",
    "# df_dicts = {}\n",
    "#\n",
    "# for index, key in np.ndenumerate(n_list_sst):\n",
    "#     df_dicts[key] = i_flag_count_list[index]\n",
    "#\n",
    "# cols = [10, 100, 500, 1000, 'n']\n",
    "#\n",
    "# print(\"Comparison table\")\n",
    "#\n",
    "# comparison_table = pd.DataFrame(df_dict)\n",
    "#\n",
    "# comparison_table = comparison_table[cols]  # Sort table columns\n",
    "# comparison_table.to_csv('results/Ktest.csv', index=False)\n",
    "# print(comparison_table)\n",
    "#\n",
    "# color_list_sst = []\n",
    "# alg_name_sst = []\n",
    "# for k_idx in range(len(K_list_sst)):\n",
    "#     if K_list_sst[k_idx] != 'i_star':\n",
    "#         alg_name_sst.append('K = ' + str(K_list_sst[k_idx]))\n",
    "#     else:\n",
    "#         alg_name_sst.append('K = Full Sample')\n",
    "#\n",
    "# avg_dual_gap = []  # avg_dual_gap[n_idx][k_idx]\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     temp_list = []\n",
    "#     for alg_idx in range(len(alg_list_sst)):\n",
    "#         temp = []\n",
    "#         for rep_idx in range(repeats_sst):  # repeats_sst == 1 code\n",
    "#             temp = stat_list_sst[n_idx][alg_idx][rep_idx].dual_gap_list[0]\n",
    "#         temp_list.append(temp)\n",
    "#     avg_dual_gap.append(temp_list)\n",
    "#\n",
    "# x_list_sst = np.arange(T_cap_sst / dual_gap_freq_sst) * dual_gap_freq_sst\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     plt.subplot(2, math.ceil(len(n_list_sst) / 2), n_idx + 1)\n",
    "#     for k_idx in range(len(alg_list_sst)):\n",
    "#         plt.plot(x_list_sst, avg_dual_gap[n_idx][k_idx], label=alg_name_sst[k_idx])\n",
    "#         plt.ylabel('Duality Gap')\n",
    "#         plt.xlabel('iterations')\n",
    "#         plt.title('n = %s Duality Gap' % n_list_sst[n_idx])\n",
    "#         plt.legend(loc=\"upper left\")\n",
    "#\n",
    "# plt.show()\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "#\n",
    "# \"\"\"\n",
    "#\n",
    "# Plot 3: Testing convergence on different K value\n",
    "#\n",
    "# Here we run for fixed T_cap, However we use optimal step-size for each case with very low epsilon 1e-8, so as to not\n",
    "# terminate before T_cap.\n",
    "#\n",
    "# \"\"\"\n",
    "#\n",
    "# # T = 100000 #Number of Total Iteration\n",
    "# J_sst = 2  # Number of Cohorts\n",
    "# L_sst = 5  # Number of Treatments\n",
    "#\n",
    "# opt_low_sst = 0  # lower bound of optimal value\n",
    "# opt_up_sst = 2  # upper bound of optimal value\n",
    "# obj_tol_sst = 1e-2  # tolerance of our objective value\\\\ tolerance of R_x and R_i, obj_tol and alg_tol should be same.\n",
    "# C_K_sst = 0.7  # proportion of epsilon that we need to pay by using i_hat\n",
    "# alpha_tol_sst = 1e-5\n",
    "# dual_gap_freq_sst = 10  # We need to set this to one in order to track duality gap at every iteration\n",
    "# # m = 3  # number of constraints, first index 0 refers to our objective function.\n",
    "# # K = 100  # Sample size of our gradient estimator\n",
    "# # K_grad = 1\n",
    "# # N = 100  # size of each uncertainty set\\\\ We are no longer using this parameter in this code\n",
    "# # n = 10 ** 2  # sample size of simulation data set, also support size of each uncertainty set.\n",
    "#\n",
    "# # nu = 0.1 # |g_t - h_t| <= nu\n",
    "# # epsilon = 0.001 #epsilon-subgradient\n",
    "#\n",
    "#\n",
    "# # Uncertainty set parameter\n",
    "# delta_sst = 0.5  # p \\geq \\delta/n\n",
    "# rho_sst = 0.01  # D_f(p,q) \\leq \\rho/n\n",
    "# nu_sst = 0.1  # Prob of high convergence\n",
    "#\n",
    "# # emp_dist_value_1 = np.random.normal(loc=0.5, scale=0.125, size=(m, J, L - 1, n))\n",
    "# # emp_dist_value_2 = np.random.normal(loc=0.25, scale=0.125, size=(m, J, 1, n))\n",
    "# # emp_dist_value = np.concatenate([emp_dist_value_1, emp_dist_value_2], axis=2)\n",
    "# # RHS = np.ones([m])\n",
    "#\n",
    "# # Get statistics of various cases.\n",
    "#\n",
    "#\n",
    "# n_list_sst = [3000]\n",
    "# K_list_sst = [1, 10, 100, 500, 1000, 1500, 'i_star']  # 6 Instance\n",
    "# K_grad_sst = 1\n",
    "# alg_list_sst = []\n",
    "# T_cap_sst = 1000\n",
    "# ss_type_sst = 'diminish'\n",
    "# var_scale_sst = 0.1\n",
    "#\n",
    "# for k_idx in range(len(K_list_sst)):\n",
    "#     temp = []\n",
    "#     temp.append(K_list_sst[k_idx])\n",
    "#     temp.append(K_grad_sst)\n",
    "#     alg_list_sst.append(temp)\n",
    "#\n",
    "# repeats_sst = 1  # Currently we don't take average here\n",
    "# m_sst = 8\n",
    "#\n",
    "# stat_list_sst = []  # stat_list_sst[n_idx][alg_idx][rep_idx]\n",
    "#\n",
    "# # Create random mean matrix for our data, [0,0.25] uniform distribution\n",
    "# mean_array_sst = np.random.rand(m_sst, J_sst, L_sst) / J_sst\n",
    "#\n",
    "# for n_num in n_list_sst:\n",
    "#     stat_alg = []\n",
    "#\n",
    "#     # Create our dataset\n",
    "#     emp_dist_value = np.zeros([m_sst, J_sst, L_sst, n_num])\n",
    "#     emp_dist_value[:] = np.nan\n",
    "#     x_0_sst = np.ones([J_sst, L_sst]) / L_sst\n",
    "#     p_0_sst = np.ones([m_sst, n_num]) / n_num\n",
    "#     RHS_sst = np.ones([m_sst])  # RHS is important for determining K!\n",
    "#\n",
    "#     # #Simple data generation\n",
    "#     # emp_dist_value_1 = np.random.normal(loc=0.5, scale=0.125, size=(m_sst, J_sst, int(L_sst / 2), n_num))\n",
    "#     # emp_dist_value_2 = np.random.normal(loc=0.25, scale=0.125, size=(m_sst, J_sst, int((L_sst + 1) / 2), n_num))\n",
    "#     # emp_dist_value = np.concatenate([emp_dist_value_1, emp_dist_value_2], axis=2)\n",
    "#\n",
    "#     # Random mean data generation\n",
    "#     emp_dist_value = np.zeros([m_sst, J_sst, L_sst, n_num])\n",
    "#     emp_dist_value[:] = np.nan\n",
    "#     for m_idx in range(m_sst):\n",
    "#         for j_idx in range(J_sst):\n",
    "#             for l_idx in range(L_sst):\n",
    "#                 emp_dist_value[m_idx, j_idx, l_idx, :] = np.random.normal(loc=mean_array_sst[m_idx, j_idx, l_idx],\n",
    "#                                                                           scale=0.125, size=n_num)\n",
    "#\n",
    "#     # Get Approximated Obj Val\n",
    "#     approx_obj_sst = 0\n",
    "#     for j_idx in range(J_sst):\n",
    "#         approx_obj_sst += np.max(mean_array_sst[0, j_idx, :])\n",
    "#\n",
    "#     print('approx_obj_sst:', approx_obj_sst)\n",
    "#     opt_up_sst = 2 * approx_obj_sst\n",
    "#\n",
    "#     G_sst = np.absolute(emp_dist_value).max()\n",
    "#     print('G:', G_sst)\n",
    "#     M_sst = []\n",
    "#     for i in range(m_sst):\n",
    "#         M_sst.append(J_sst * np.absolute(emp_dist_value[i, :, :, :]).max())\n",
    "#\n",
    "#     for alg_idx in range(len(alg_list_sst)):\n",
    "#         stat_repeat = []\n",
    "#         K_sst = 0\n",
    "#         K_grad_sst = 0\n",
    "#\n",
    "#         if alg_list_sst[alg_idx][0] == 'i_star':\n",
    "#             K_sst = n_num\n",
    "#         else:\n",
    "#             K_sst = alg_list_sst[alg_idx][0]\n",
    "#\n",
    "#         if alg_list_sst[alg_idx][1] == 'FGD':\n",
    "#             K_grad_sst = n_num\n",
    "#         else:\n",
    "#             K_grad_sst = alg_list_sst[alg_idx][1]\n",
    "#\n",
    "#         if K_sst == n_num:\n",
    "#             C_K_sst = 1\n",
    "#\n",
    "#         random_samples_list = np.random.rand(T_cap_sst, m_sst, K_sst)\n",
    "#\n",
    "#         # Repeat on the same dataset we have\n",
    "#         for rep_idx in range(repeats_sst):\n",
    "#             print(\"K_sst:\", K_sst)\n",
    "#             alg_stat = DRO_Solver(x_0_sst, p_0_sst, emp_dist_value, K_sst, K_grad_sst, 'entropy', 'chi-square',\n",
    "#                                   delta_sst, rho_sst, nu_sst, alpha_tol_sst, opt_low_sst, opt_up_sst,\n",
    "#                                   obj_tol_sst, RHS_sst, ss_type_sst, random_samples_list, C_K_sst, \\\n",
    "#                                   dual_gap_freq_sst, T_cap_sst, print_option=0, K_test_flag=1, min_flag=0)\n",
    "#\n",
    "#             stat_repeat.append(alg_stat)\n",
    "#         stat_alg.append(stat_repeat)\n",
    "#     stat_list_sst.append(stat_alg)\n",
    "#\n",
    "# # Draw plot 3\n",
    "#\n",
    "# # stat_list_sst[n_idx][alg_idx or k_idx][rep_idx]\n",
    "#\n",
    "# # Draw some plot here.\n",
    "# # We also need to consider early termination than T_cap!\n",
    "#\n",
    "#\n",
    "# i_flag_count_list = []\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     temp_list = []\n",
    "#     for alg_idx in range(len(alg_list_sst)):\n",
    "#         for rep_idx in range(repeats_sst):  # repeats_sst == 1 code\n",
    "#             temp = stat_list_sst[n_idx][alg_idx][rep_idx].i_flag_count\n",
    "#         temp_list.append(temp)\n",
    "#     i_flag_count_list.append(temp_list)\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     print('i flag count when n = %s' % n_list_sst[n_idx])\n",
    "#     for k_idx, value in enumerate(i_flag_count_list[n_idx]):\n",
    "#         print('K value: %s, i_flag_count: %s ' % (K_list_sst[k_idx], value))\n",
    "#\n",
    "# color_list_sst = []\n",
    "# alg_name_sst = []\n",
    "# for k_idx in range(len(K_list_sst)):\n",
    "#     if K_list_sst[k_idx] != 'i_star':\n",
    "#         alg_name_sst.append('K = ' + str(K_list_sst[k_idx]))\n",
    "#     else:\n",
    "#         alg_name_sst.append('K = Full Sample')\n",
    "#\n",
    "# avg_dual_gap = []  # avg_dual_gap[n_idx][k_idx]\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     temp_list = []\n",
    "#     for alg_idx in range(len(alg_list_sst)):\n",
    "#         temp = []\n",
    "#         for rep_idx in range(repeats_sst):  # repeats_sst == 1 code\n",
    "#             temp = stat_list_sst[n_idx][alg_idx][rep_idx].dual_gap_list[0]\n",
    "#         temp_list.append(temp)\n",
    "#     avg_dual_gap.append(temp_list)\n",
    "#\n",
    "# x_list_sst = np.arange(T_cap_sst / dual_gap_freq_sst) * dual_gap_freq_sst\n",
    "#\n",
    "# for n_idx in range(len(n_list_sst)):\n",
    "#     plt.subplot(2, math.ceil(len(n_list_sst) / 2), n_idx + 1)\n",
    "#     for k_idx in range(len(alg_list_sst)):\n",
    "#         plt.plot(x_list_sst, avg_dual_gap[n_idx][k_idx], label=alg_name_sst[k_idx])\n",
    "#         plt.ylabel('Duality Gap')\n",
    "#         plt.xlabel('iterations')\n",
    "#         plt.title('n = %s Duality Gap' % n_list_sst[n_idx])\n",
    "#         plt.legend(loc=\"upper left\")\n",
    "#\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
