{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "%run UBRegret.ipynb\n",
    "%run utils.ipynb\n",
    "\n",
    "\n",
    "#Todo\n",
    "\"\"\"\n",
    "1. Go through Full_alpha function\n",
    "2. Saving p value in tree structure? --> This is the most important thing.\n",
    "3. Update dual_gap_freq to fraction. like 1/20.. --> Complete this today. \n",
    "5. Frequent update of x and p and x_bar and p_bar --> Complete this today. \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Here, we use following structure to save previous solutions and update p_bar and x_bar.\n",
    "We have 4 options for the DRO_SMD algorithm. This code is incomplete. \n",
    "x = np.empty([dual_gap_freq,J,L])\n",
    "x[0,:,:] = x_0\n",
    "p = np.empty([dual_gap_freq, m, n])\n",
    "p[0,:,:] = p_0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Update Notes:\n",
    "Oct-11\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Define Stochastic Mirror Descent function for x\n",
    "K: Sample size of our gradient \n",
    "m: Number of constraints\n",
    "prox: prox function\n",
    "p:current uncertainty parameter matrix, matrix form is m x J x L x N\n",
    "alpha: step-size\n",
    "x: current x\n",
    "RHS: RHS of the constraint, for the first constraint(i=0) RHS is objective value that we are \n",
    "currently bisecting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMD_x(K, K_grad, x, step_alpha, samples_list, grad_samples_list, RHS, emp_dist_value, w_sum, cum_dist):\n",
    "    \"\"\"\n",
    "    When Prox function is entropy function\n",
    "    If we use chi-square as a f-divergence, we need to relax our uncertainty set according to\n",
    "    Duchi's paper\n",
    "    \"\"\"\n",
    "    # Get the value of m,J,L,n\n",
    "    m, J, L, n = emp_dist_value.shape\n",
    "    g_t = np.zeros([J, L])  # subgradient estimator\n",
    "    F_hat = []\n",
    "\n",
    "    \"\"\"\n",
    "    i_hat calculation\n",
    "    \"\"\"\n",
    "    K_samples = np.zeros([m, K])\n",
    "\n",
    "    # Pick K samples from each constraint, and j and l.\n",
    "    for i in range(m):\n",
    "        K_samples[i, :] = np.digitize(samples_list[i, :], cum_dist[i, :])\n",
    "\n",
    "    K_samples = np.where(K_samples >= n, n - 1, K_samples)\n",
    "\n",
    "    \"\"\"\n",
    "    Compute hat(F)^{i,K} for each constraint i\n",
    "    hat(F)^{i,K} = 1/K* sum_{j=1}^K F^i(x_t,z^{i,I_j^i})\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "        temp = 0\n",
    "        temp = w_sum[i] * np.sum(np.multiply(np.sum(emp_dist_value[i, :, :, :][:, :, K_samples[i, :].astype(int)], \\\n",
    "                                                     axis=2), x))\n",
    "        temp = temp / K - RHS[i]\n",
    "        F_hat.append(temp)\n",
    "    # get the index of max value in list F_hat\n",
    "    i_hat = F_hat.index(max(F_hat))\n",
    "\n",
    "    \"\"\"\n",
    "    g_t calculation\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    K_grad_samples = np.zeros(K_grad)\n",
    "    K_grad_samples[:] = np.digitize(grad_samples_list, cum_dist[i_hat, :])\n",
    "    K_grad_samples = np.where(K_grad_samples >= n, n - 1, K_grad_samples)\n",
    "    for k_idx in range(K_grad):\n",
    "        g_t += w_sum[i_hat] * emp_dist_value[i_hat, :, :, int(K_grad_samples[k_idx])] / K_grad\n",
    "\n",
    "    \"\"\"\n",
    "    x_{t+1} calculation\n",
    "    \"\"\"\n",
    "\n",
    "    # Get next x (Projection Step with entropy prox function)\n",
    "    theta = np.multiply(x, np.exp(-step_alpha*g_t))\n",
    "    x_update = np.zeros([J, L])\n",
    "    for j in range(J):\n",
    "        x_update[j, :] = theta[j, :] / np.sum(theta[j, :])\n",
    "\n",
    "    return x_update, np.array(F_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMD_x_K_test(K, K_grad, x, p, step_alpha, samples_list, grad_samples_list, RHS, emp_dist_value, w_sum, cum_dist):\n",
    "    \"\"\"\n",
    "    When Prox function is entropy function\n",
    "    If we use chi-square as a f-divergence, we need to relax our uncertainty set according to\n",
    "    Duchi's paper\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-4\n",
    "\n",
    "    # Get the value of m,J,L,n\n",
    "    m, J, L, n = emp_dist_value.shape\n",
    "    g_t = np.zeros([J, L])  # subgradient estimator\n",
    "    F_hat = []\n",
    "    F_hat_real = []\n",
    "    i_hat_flag = 0\n",
    "\n",
    "    \"\"\"\n",
    "    i_hat calculation\n",
    "    \"\"\"\n",
    "    K_samples = np.zeros([m, K])\n",
    "\n",
    "    # Pick K samples from each constraint, and j and l.\n",
    "    for i in range(m):\n",
    "        K_samples[i, :] = np.digitize(samples_list[i, :], cum_dist[i, :])\n",
    "\n",
    "    K_samples = np.where(K_samples >= n, n - 1, K_samples)\n",
    "\n",
    "    \"\"\"\n",
    "    Compute hat(F)^{i,K} for each constraint i\n",
    "    hat(F)^{i,K} = 1/K* sum_{j=1}^K F^i(x_t,z^{i,I_j^i})\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "        temp = 0\n",
    "        temp = w_sum[i] * np.sum(np.multiply(np.sum(emp_dist_value[i, :, :, :][:, :, K_samples[i, :].astype(int)], \\\n",
    "                                                     axis=2), x))\n",
    "        temp = temp / K - RHS[i]\n",
    "        F_hat.append(temp)\n",
    "    # get the index of max value in list F_hat\n",
    "    i_hat = F_hat.index(max(F_hat))\n",
    "\n",
    "    for i in range(m):\n",
    "        temp = 0\n",
    "        temp = np.sum(np.multiply(np.tensordot(p[i, :], emp_dist_value[i, :, :, :], axes=(0, 2)), x))\n",
    "        temp = temp - RHS[i]\n",
    "        F_hat_real.append(temp)\n",
    "\n",
    "    i_star = F_hat_real.index(max(F_hat_real))\n",
    "\n",
    "    \"\"\"\n",
    "    i_hat and i_star comparison\n",
    "    \"\"\"\n",
    "\n",
    "    if abs(F_hat_real[i_star] -F_hat[i_hat]) <= eps:\n",
    "        i_hat_flag = 1\n",
    "\n",
    "    \"\"\"\n",
    "    g_t calculation\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    K_grad_samples = np.zeros(K_grad)\n",
    "    K_grad_samples[:] = np.digitize(grad_samples_list, cum_dist[i_hat, :])\n",
    "    K_grad_samples = np.where(K_grad_samples >= n, n - 1, K_grad_samples)\n",
    "    for k_idx in range(K_grad):\n",
    "        g_t += w_sum[i_hat] * emp_dist_value[i_hat, :, :, int(K_grad_samples[k_idx])] / K_grad\n",
    "\n",
    "    \"\"\"\n",
    "    x_{t+1} calculation\n",
    "    \"\"\"\n",
    "\n",
    "    # Get next x (Projection Step with entropy prox function)\n",
    "    theta = np.multiply(x, np.exp(-step_alpha*g_t))\n",
    "    x_update = np.zeros([J, L])\n",
    "    for j in range(J):\n",
    "        x_update[j, :] = theta[j, :] / np.sum(theta[j, :])\n",
    "\n",
    "    return x_update, np.array(F_hat), i_hat_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_alpha(p_val, w_t, I_t, n, delta, rho, w_sum, w_square_sum):\n",
    "    \"\"\"\n",
    "    Input w_sum and w_square_sum are sum of p[t] and square sum of p[t].\n",
    "    So, we need to perform an additional update on these values.\n",
    "\n",
    "    \"\"\"\n",
    "    #Our input w_sum and w_square_sum is not updated. So we need to update before we proceed.\n",
    "\n",
    "    alpha_up = 1\n",
    "    alpha_low = 0\n",
    "    g_alpha = 1\n",
    "\n",
    "    # values when w_t[I_t]>= w_threshold, I(alpha) = [n]\n",
    "    w_sum2 = w_sum - p_val + w_t[I_t]\n",
    "    w_square_sum2 = w_square_sum - p_val ** 2 + w_t[I_t] ** 2\n",
    "    I_alpha2 = n\n",
    "\n",
    "    # values when w_t[I_t]< w_threshold, I(alpha) = [n]\\[I_t]\n",
    "    w_sum1 = w_sum - p_val\n",
    "    w_square_sum1 = w_square_sum - p_val ** 2\n",
    "    I_alpha1 = n - 1\n",
    "\n",
    "    if w_t[I_t] >= delta/n:\n",
    "        if w_square_sum2 / 2 - w_sum2 / n + 1/(2*n) < rho/ n**2:\n",
    "            alpha = 0\n",
    "            return alpha\n",
    "        else:\n",
    "            alpha = 1 - math.sqrt(rho/(n**2 * (w_square_sum2 / 2 - w_sum2 / n + 1/(2*n))))\n",
    "            return alpha\n",
    "\n",
    "    alpha_thre = (delta/n - w_t[I_t]) / (1/n - w_t[I_t])\n",
    "\n",
    "    while True:\n",
    "\n",
    "        alpha = (alpha_up + alpha_low) / 2\n",
    "\n",
    "\n",
    "        if alpha >= alpha_thre: #I(alpha) = [n]\n",
    "            w_sum = w_sum2\n",
    "            w_square_sum = w_square_sum2\n",
    "            I_alpha = I_alpha2\n",
    "        else: #I(alpha) = [n]\\I_t\n",
    "            w_sum = w_sum1\n",
    "            w_square_sum = w_square_sum1\n",
    "            I_alpha = I_alpha1\n",
    "\n",
    "        #Calculate g'(alpha)\n",
    "        g_alpha = w_square_sum / 2 - w_sum / n + I_alpha * ((1 - alpha) ** 2 - (1 - delta) ** 2) / (2 * (n ** 2) * \\\n",
    "                (1 - alpha) ** 2) + (n * (1 - delta) ** 2 - 2 * rho) / (2 * (n ** 2) * (1 - alpha) ** 2)\n",
    "\n",
    "        #Update the interval according to the g'(alpha) value\n",
    "        if g_alpha < 0:\n",
    "            alpha_up = alpha\n",
    "        else:\n",
    "            alpha_low = alpha\n",
    "\n",
    "        #termination condition\n",
    "        if alpha_low > alpha_thre: #I(alpha) = [n]\n",
    "            if w_square_sum2 /2 - w_sum2/n + 1/(2*n) < rho/n**2:\n",
    "                alpha = 0\n",
    "                return alpha\n",
    "            else:\n",
    "                alpha = 1 - math.sqrt(rho/(n**2 * (w_square_sum2 / 2 - w_sum2 / n + 1/(2*n))))\n",
    "                #raise TypeError('Returning case 1')\n",
    "                return alpha\n",
    "        elif alpha_up <= alpha_thre:\n",
    "            if w_square_sum1 / 2 - w_sum1 / n + (n-1)/(2*n**2) <= rho/n**2 - (1-delta)**2 / (2*n**2):\n",
    "                alpha = 0\n",
    "                return alpha\n",
    "            else:\n",
    "                alpha = 1 - math.sqrt((rho/n**2 - (1-delta)**2 / (2*n**2))/(w_square_sum1 / 2 - w_sum1 / n + (n-1)/(2*n**2)))\n",
    "                #raise TypeError('Returning case 2')\n",
    "                return alpha\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Construct A_i for each i\n",
    "We do not utilize tree structure here. \n",
    "prox function follows divergence of our problem\n",
    "Here i is a index of constraint\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# In[10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMD_p(x, p, i, step_alpha, delta, rho, alpha_tol, emp_dist_value, w_sum, w_square_sum, cum_dist):\n",
    "    # for each constraint and JL sample one index I_t ~ p_t^i\n",
    "    # If we are using chi-square as our f-divergence, we need to relax our uncertainty set.\n",
    "    _, J, L, n = emp_dist_value.shape\n",
    "\n",
    "    #Sample an index\n",
    "    random_num = np.random.rand()\n",
    "    I_t = np.digitize(random_num, cum_dist)\n",
    "\n",
    "    if I_t >=n:\n",
    "        I_t -=1\n",
    "\n",
    "    grad_val = np.sum(np.multiply(x, emp_dist_value[i, :, :, I_t])) * w_sum / p[I_t]\n",
    "    old_pval = p[I_t]\n",
    "    #update p_t to w_t\n",
    "    p[I_t] += step_alpha * grad_val\n",
    "    w_temp = p[I_t]\n",
    "    # Projection to our chi-square uncertainty set\n",
    "    # We are not using tree structure here.\n",
    "    # Note that g'(alpha) is a decreasing function of alpha\n",
    "    # Input w_sum and w_square_sum are sum of p[t] and square sum of p[t].\n",
    "    alpha = find_alpha(old_pval, p, I_t, n, delta, rho, w_sum, w_square_sum)\n",
    "\n",
    "    # Update p value according to alpha that we find above\n",
    "    # For i != I_t, p_{t+1} = (1-alpha)w_i + alpha/n, Can we reduce this process to O(log n)\n",
    "    p *= (1 - alpha)\n",
    "    p += alpha / n\n",
    "\n",
    "    #Update cumulative distribution\n",
    "    v1 = alpha * (np.arange(n) + 1) / n # We need to work on this\n",
    "    # For i = I_t, we should first take a look at w_{t,I_t}\n",
    "    # Also update cumulative distribution vector here.\n",
    "\n",
    "    if p[I_t] < delta / n:\n",
    "        gamma = (delta - alpha) / n - (1 - alpha) * old_pval\n",
    "        temp1 = np.zeros(I_t)\n",
    "        temp2 = gamma * np.ones(n - I_t)\n",
    "\n",
    "        v2 = np.concatenate((temp1, temp2))\n",
    "        cum_dist *= (1 - alpha) * w_sum\n",
    "        cum_dist += (v1+v2)\n",
    "        p[I_t] = delta / n\n",
    "        w_square_sum = (1 - alpha) ** 2 * (w_square_sum - old_pval ** 2) + 2 * (1 - alpha) * alpha * \\\n",
    "                       (w_sum - old_pval) / n + (n - 1) * alpha ** 2 / n ** 2 + delta ** 2 / n ** 2\n",
    "        w_sum = (1 - alpha) * (w_sum - old_pval) + (n - 1) * alpha / n + delta / n\n",
    "        cum_dist /= w_sum\n",
    "    # check whether the two value is correct.\n",
    "    else:  # p_new[I_t] > delta/n\n",
    "        cum_dist *= (1 - alpha) * w_sum\n",
    "        cum_dist += v1\n",
    "        w_sum = w_sum + step_alpha * grad_val\n",
    "        cum_dist /= w_sum\n",
    "\n",
    "        w_square_sum = w_square_sum - old_pval ** 2 + w_temp ** 2 #Recheck this part later.\n",
    "        w_square_sum = (1 - alpha) ** 2 * w_square_sum + 2 * alpha * (1 - alpha) * w_sum / n + alpha ** 2 / n\n",
    "        w_sum = (1 - alpha) * w_sum + alpha\n",
    "\n",
    "    \"\"\"\n",
    "    #Check whether our modification is correct.\n",
    "    if np.sum(p_new[j,l,:])!= w_sum[j,l]:\n",
    "        print(np.sum(p_new[j,l,:]))\n",
    "        print(w_sum[j,l])\n",
    "        raise TypeError(\"w_sum not equal\")\n",
    "    if np.sum(p_new[j,l,:]**2)!= w_square_sum[j,l]:\n",
    "        print(np.sum(p_new[j,l,:]**2))\n",
    "        print(w_square_sum[j,l])\n",
    "        raise TypeError(\"w_square_sum not equal\")\n",
    "    \"\"\"\n",
    "\n",
    "    return p, w_sum, w_square_sum, cum_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRO_SMD(x_0, p_0, emp_dist_value, K, K_grad, delta, rho, alpha_tol, opt_low, opt_up, obj_tol,\n",
    "        RHS,ss_type, C_K, dual_gap_option, dual_gap_freq, T_cap, print_option=1, K_test_flag=0, min_flag=1,feas_opt = 0):\n",
    "    # Change data according to min_flag.\n",
    "    \"\"\"\n",
    "    If dual_gap_option == 0: then don't calculate dual_gap and use absolute dual_gap_freq.\n",
    "    If dual_gap_option == 1: then don't calculate dual_gap and use relative dual_gap_freq.\n",
    "    If dual_gap_option == 2: then calculate dual_gap and use absolute dual_gap_freq.\n",
    "    If dual_gap_option == 3: then calculate dual_gap and use relative dual_gap_freq.\n",
    "    \"\"\"\n",
    "\n",
    "    emp_dist_value_copy = emp_dist_value.copy()\n",
    "    emp_dist_value_copy[0, :, :, :] = (-1 + 2 * min_flag) * emp_dist_value_copy[0, :, :, :]\n",
    "\n",
    "    m, J, L, n = emp_dist_value.shape  # Parameters\n",
    "\n",
    "    # Calculate coefficients\n",
    "\n",
    "    C_G = 1 + math.sqrt(rho / n)\n",
    "\n",
    "    print('\\n')\n",
    "    print('************************************************************************************')\n",
    "    print('*******************************Problem Description**********************************')\n",
    "    print(' ')\n",
    "    print('Number of constraints: %s, x dimension: %s ,Uncertainty Set Dimension: %s' % (m, J * L, n))\n",
    "    print(' ')\n",
    "    print('*************************************************************************************')\n",
    "    print('*************************************************************************************')\n",
    "\n",
    "    i_flag_count = 0\n",
    "\n",
    "    if K_test_flag:\n",
    "        print('We are doing sample size test here!')\n",
    "\n",
    "    stoc_factor = 1  # We need to adjust this part later Sep-20\n",
    "\n",
    "    # G is bound of norm of gradient(\\nabla) F_k^i(x) for all k \\in [n] and i \\in [m] and x \\in X\n",
    "    G = np.absolute(emp_dist_value).max()  # Also, need to change this funciton add C2\n",
    "    # M is an list of bound of |F_k^i(x)| for each i \\in [m]\n",
    "    absolute_max = np.absolute(emp_dist_value).max(axis=2)\n",
    "    sum_over_J = np.sum(absolute_max, axis=1)\n",
    "    M = sum_over_J.max(axis=1)\n",
    "\n",
    "    # Calculate T and our stepsize\n",
    "    if ss_type == 'constant':\n",
    "        T, R_x, R_p, ss_x, ss_p = R_const_SMD(J, L, n, G, M, delta, rho, obj_tol, C_G, C_K, stoc_factor)\n",
    "        if K_test_flag:\n",
    "            print(\"Max Iteration:\", T_cap)\n",
    "            print('alg_type:SGD with i_hat')\n",
    "            T = T_cap\n",
    "            obj_tol = 1e-7\n",
    "            ss_x_list = ss_x * np.ones(T + 1)\n",
    "            ss_p_list = []\n",
    "            for i in range(m):\n",
    "                ss_p_list.append(ss_p[i] * np.ones(T + 1))\n",
    "        else:\n",
    "            print(\"Max Iteration:\", T)\n",
    "            print('alg_type:SGD with i_hat')\n",
    "            ss_x_list = ss_x * np.ones(T + 1)\n",
    "            ss_p_list = []\n",
    "            for i in range(m):\n",
    "                ss_p_list.append(ss_p[i] * np.ones(T + 1))\n",
    "\n",
    "\n",
    "\n",
    "    elif ss_type == 'diminish':\n",
    "        T, R_x, R_p, c_x, c_p = R_dim_SMD(J, L, n, G, M, delta, rho, obj_tol, C_G, C_K,\n",
    "                                          stoc_factor)\n",
    "        if K_test_flag:\n",
    "            print(\"Max Iteration:\", T_cap)\n",
    "            print('alg_type:SGD with i_hat')\n",
    "            T = T_cap\n",
    "            ss_x_list = c_x * (np.sqrt(1 / (np.arange(T + 1) + 1)))\n",
    "            obj_tol = 1e-7\n",
    "            ss_p_list = []\n",
    "            for i in range(m):\n",
    "                ss_p_list.append(c_p[i] * (np.sqrt(1 / (np.arange(T + 1) + 1))))\n",
    "\n",
    "        else:\n",
    "            print(\"Max Iteration:\", T)\n",
    "            print('alg_type:SGD with i_hat')\n",
    "            ss_x_list = c_x * (np.sqrt(1 / (np.arange(T + 1) + 1)))\n",
    "            ss_p_list = []\n",
    "            for i in range(m):\n",
    "                ss_p_list.append(c_p[i] * (np.sqrt(1 / (np.arange(T + 1) + 1))))\n",
    "    print('Rx: %s' % R_x)\n",
    "    print('Rp: %s' % R_p)\n",
    "\n",
    "    # This String List would be used on inf_pi function\n",
    "    constr_list = []\n",
    "    for i in range(m):\n",
    "        constr_list.append('obj_' + str(i))\n",
    "\n",
    "    bisection = []\n",
    "    bisection_count = 0\n",
    "\n",
    "    vartheta_list = []\n",
    "\n",
    "    # x_coeff,_ = get_coeff(emp_dist_value_copy,rho,delta, alpha_tol)\n",
    "    # print(x_coeff)\n",
    "    # Define a PWL to calculate inf_pi\n",
    "    list_J = list(range(J))\n",
    "    list_L = list(range(L))\n",
    "\n",
    "    PWL_model = gp.Model('PWL')\n",
    "\n",
    "    PWL_model.setParam('OutputFlag', 0)\n",
    "    var_t = PWL_model.addVar(lb=-GRB.INFINITY, name='t')\n",
    "    var_x = PWL_model.addVars(list_J, list_L, ub=1, name='x')\n",
    "    PWL_model.addConstrs(gp.quicksum(var_x[j, l] for l in list_L) == 1 for j in list_J)\n",
    "\n",
    "    # Create dummy constraints\n",
    "    for i in range(m):\n",
    "        PWL_model.addConstr(var_t >= i, name=constr_list[i])\n",
    "\n",
    "    obj = var_t\n",
    "\n",
    "    PWL_model.setObjective(obj, GRB.MINIMIZE)\n",
    "    PWL_model.optimize()\n",
    "\n",
    "    dual_gap_list = []  # each element is a list of dual gap at each bisection iteration\n",
    "    iter_timer_list = []  # each element  elapsed time per bisection\n",
    "    real_T_list = []  # each element is a list of terminated iteration by dual gap condition at each\n",
    "    # bisection iteration\n",
    "    early_term_count = 0\n",
    "\n",
    "\n",
    "    total_tic = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    sample_freq = 10 ** 5  # We can move this to parameter.\n",
    "    sanity_check = 0\n",
    "    sanity_freq = 1000\n",
    "\n",
    "    if dual_gap_option == 2 or dual_gap_option == 0:\n",
    "        pass\n",
    "    elif dual_gap_option ==3 or dual_gap_option == 1:\n",
    "        dual_gap_freq = int(T * dual_gap_freq)\n",
    "\n",
    "    #Set calculation option\n",
    "    if dual_gap_option == 0 or dual_gap_option == 1:\n",
    "        dual_gap_cal = 0\n",
    "    else:\n",
    "        dual_gap_cal = 1\n",
    "\n",
    "\n",
    "    #Check Whether hat_vartheta is approximating well.\n",
    "    vartheta_flag = 0\n",
    "    feas_flag = 0\n",
    "    # Implementing normal test\n",
    "    if K_test_flag == 0:\n",
    "\n",
    "        while opt_up - opt_low > obj_tol and not feas_flag:\n",
    "            iter_tic = time.time()\n",
    "            feas_flag = feas_opt\n",
    "            break_flag = 0\n",
    "            bisection_count += 1\n",
    "\n",
    "            # Change our objective function\n",
    "            obj_val = (opt_up + opt_low) / 2\n",
    "            RHS[0] = (-1 + 2 * min_flag) * obj_val\n",
    "            if print_option:\n",
    "                print('---------------------------')\n",
    "                print('%s-th bisection iteration' % bisection_count)\n",
    "                print('alg_type:SGD with i_hat')\n",
    "                print('---------------------------')\n",
    "                print(\"current step objective value:\", obj_val)\n",
    "\n",
    "            #If dual_gap_freq == 0, then we do not save previous output\n",
    "            #Todo\n",
    "            #We are saving x_t only. Exclude this step when it is needed.\n",
    "            x = np.empty([dual_gap_freq,J,L])\n",
    "            x[0,:,:] = x_0\n",
    "            p = np.empty([dual_gap_freq, m, n])\n",
    "            p[0,:,:] = p_0\n",
    "\n",
    "            hat_f_val = np.zeros([dual_gap_freq,m])\n",
    "            hat_f_val_ws = np.zeros(m)\n",
    "\n",
    "\n",
    "            #Variables that is needed to update periodically.\n",
    "            iter_count = 0\n",
    "            ss_sum_x = 0\n",
    "            ss_sum_p = 0 #This does not have to be np.zeros([m])\n",
    "            x_ws = np.zeros([J,L])\n",
    "            p_ws = np.zeros([m,n])\n",
    "            if vartheta_flag:\n",
    "                real_f_val = np.zeros([dual_gap_freq, m])\n",
    "                real_f_val_ws = np.zeros(m)\n",
    "\n",
    "\n",
    "            # Get x and p for T iterations\n",
    "            tic = time.time()\n",
    "\n",
    "            w_sum = np.zeros(m)\n",
    "            w_sum[:] = np.nan\n",
    "            w_square_sum = np.zeros(m)\n",
    "            w_square_sum[:] = np.nan\n",
    "            cum_dist = np.zeros([m, n])\n",
    "            cum_dist[:] = np.nan\n",
    "\n",
    "            for i in range(m):\n",
    "                w_sum[i] = np.sum(p_0[i, :])\n",
    "                w_square_sum[i] = np.sum(p_0[i, :] ** 2)\n",
    "                cum_dist[i, :] = np.cumsum(p_0[i, :])\n",
    "\n",
    "            dual_gap = []  # List that contains duality gap in this bisection\n",
    "\n",
    "            # if dual_gap_freq == 0 : #We also need to update this value periodically.\n",
    "            #\n",
    "            #     for i in range(m):\n",
    "            #         f_val[i] += np.sum(np.multiply(np.tensordot(p_old[i, :],emp_dist_value_copy[i, :, :, :], \\\n",
    "            #                                                                  axes=(0, 2)), x_list[0])) * ss_x_list[0]\n",
    "\n",
    "\n",
    "            for t in range(T):\n",
    "\n",
    "                # Now our step-size is not uniform. Make sure to change x_bar and p_bar according to our step size\n",
    "                # Create samples\n",
    "                if t % sample_freq == 0:\n",
    "                    temp_samples_list = np.random.rand(m, K, sample_freq)\n",
    "                    grad_samples_list = np.random.rand(K_grad, sample_freq)\n",
    "\n",
    "\n",
    "                #hat_vartheta sanity check\n",
    "\n",
    "                if vartheta_flag:\n",
    "                    real_F_hat = []\n",
    "                    for i in range(m):\n",
    "                        temp = 0\n",
    "                        temp = np.sum(np.multiply(np.tensordot(p[t%dual_gap_freq,i, :], emp_dist_value_copy[i, :, :, :],\\\n",
    "                            axes=(0, 2)), x[t%dual_gap_freq,:,:]))\n",
    "                        temp = temp - RHS[i]\n",
    "                        real_F_hat.append(temp)\n",
    "                    real_f_val[t%dual_gap_freq,:] = np.array(real_F_hat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if print_option and (t+2)%dual_gap_freq ==0:\n",
    "                    toc = time.time()\n",
    "                    print('=========================================')\n",
    "                    print('%s-st iteration start time:' % (t + 1), toc - tic)\n",
    "                #We do not need information of p_t here. Only cumdist and w_sum is needed.\n",
    "                x[(t+1)%dual_gap_freq,:,:],hat_f_val[t%dual_gap_freq,:] = SMD_x(K, K_grad, x[t%dual_gap_freq,:,:],\\\n",
    "                    ss_x_list[t], temp_samples_list[:, :, t % sample_freq], grad_samples_list[:,t % sample_freq],RHS, \\\n",
    "                        emp_dist_value_copy, w_sum, cum_dist)\n",
    "\n",
    "                for i in range(m):\n",
    "                    p[(t+1)%dual_gap_freq,i,:], w_sum[i], w_square_sum[i], cum_dist[i, :] = \\\n",
    "                        SMD_p(x[t%dual_gap_freq,:,:], p[t%dual_gap_freq,i,:], i,ss_p_list[i][t], delta,rho, alpha_tol, \\\n",
    "                          emp_dist_value_copy, w_sum[i], w_square_sum[i], cum_dist[i, :])\n",
    "\n",
    "                #Sanity Check\n",
    "                # if dual_gap_freq == 0 and sanity_check:\n",
    "                #     p.append(p_old)\n",
    "                #     if t % sanity_freq == 0:\n",
    "                #         x_bar = bar_calculator(x, t + 2, ss_x_list)\n",
    "                #         p_bar = bar_calculator(p, t + 2, ss_p_list[0])\n",
    "                #         sup_val = sup_pi(x_bar, emp_dist_value_copy, rho, delta, alpha_tol, RHS)\n",
    "                #         inf_val = inf_pi(p_bar, emp_dist_value_copy, RHS, PWL_model, var_t, var_x, constr_list)\n",
    "                #         diff = sup_val - inf_val\n",
    "                #         dual_gap.append(diff)\n",
    "                #         print(\"%s-st iteration duality gap:\" % (t + 1), diff)\n",
    "                #         # print(\"x_bar:\", x_bar)\n",
    "                #         # print(\"p_bar[0,0,0,:]:\",p_bar[0,0,0,:])\n",
    "                #         # print(\"p_new[0,0,0:]:\", p_new[0,0,:])\n",
    "                #         # print(\"X Coeff:\", temp_coeff)\n",
    "                #         print(\"sup_val:\", sup_val)\n",
    "                #         print(\"inf_val:\", inf_val)\n",
    "                #         if K_grad < n:\n",
    "                #             print(\"w_sum:\", w_sum)\n",
    "                #         else:\n",
    "                #             print('w_sum:',\n",
    "                #                   np.sum(p[t + 1], axis=1))  # We need to turn this print option later.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \"\"\"\n",
    "    \n",
    "                Duality Gap Termination Condition(Implement when dual_flag != 0)\n",
    "    \n",
    "                \"\"\"\n",
    "                # Calculate Dual gap\n",
    "                if dual_gap_cal and (t + 2) % dual_gap_freq == 0:\n",
    "                    dual_gap_tic = time.time()\n",
    "                    x_ws, ss_sum_x = bar_calculator_temp(x_ws, x, dual_gap_freq,\\\n",
    "                        ss_x_list[iter_count * dual_gap_freq:(iter_count+1) * dual_gap_freq],ss_sum_x)\n",
    "                    p_ws, ss_sum_p = bar_calculator_temp(p_ws,p, dual_gap_freq,\\\n",
    "                                ss_p_list[0][iter_count * dual_gap_freq:(iter_count+1) * dual_gap_freq],ss_sum_p)\n",
    "                    sup_val = sup_pi(x_ws/ss_sum_x, emp_dist_value_copy, rho, delta, alpha_tol, RHS)\n",
    "                    inf_val = inf_pi(p_ws/ss_sum_p, emp_dist_value_copy, RHS, PWL_model, var_t, var_x, constr_list)\n",
    "                    diff = sup_val - inf_val\n",
    "                    dual_gap.append(diff)\n",
    "                    dual_gap_toc = time.time()\n",
    "\n",
    "                if dual_gap_cal and (t+2) % dual_gap_freq == 0 and print_option:\n",
    "                    print(\"%s-st iteration duality gap:\" % (t + 1), diff)\n",
    "                    print(\"Dual Gap Calculation Time %s\" %(dual_gap_toc - dual_gap_tic))\n",
    "                    # print(\"x_bar:\", x_bar)\n",
    "                    # print(\"p_bar[0,0,0,:]:\",p_bar[0,0,0,:])\n",
    "                    # print(\"p_new[0,0,0:]:\", p_new[0,0,:])\n",
    "                    # print(\"X Coeff:\", temp_coeff)\n",
    "                    print(\"sup_val:\", sup_val)\n",
    "                    print(\"inf_val:\", inf_val)\n",
    "                    if K_grad < n:\n",
    "                        print(\"w_sum:\", w_sum)\n",
    "\n",
    "                \"\"\"\n",
    "    \n",
    "                Update hat_f_val_ws every dual_gap_freq iteration.\n",
    "    \n",
    "                \"\"\"\n",
    "                # Whether dual_gap_cal ==0 or not, we calculate hat_f_val_ws. Also, this update comes later than dual\n",
    "                # gap calculation, so we increase our iter_count here.\n",
    "                if (t + 1) % dual_gap_freq == 0:\n",
    "                    hat_f_val_ws += np.tensordot(hat_f_val, ss_x_list[iter_count * dual_gap_freq: \\\n",
    "                                                                      (iter_count + 1) * dual_gap_freq], axes=(0, 0))\n",
    "\n",
    "                    if vartheta_flag:\n",
    "\n",
    "                        real_f_val_ws +=np.tensordot(real_f_val, ss_x_list[iter_count * dual_gap_freq: \\\n",
    "                                                                          (iter_count + 1) * dual_gap_freq], axes=(0, 0))\n",
    "                    iter_count += 1\n",
    "\n",
    "\n",
    "                #If K_test_flag == 1, we don't use duality gap termination condition\n",
    "                if dual_gap_cal and (t+2) % dual_gap_freq == 0 and diff <= obj_tol / 2:\n",
    "                    real_t = t + 1\n",
    "                    break_flag = 1\n",
    "                    iter_toc = time.time()\n",
    "                    dual_gap_list.append(dual_gap)\n",
    "                    iter_timer_list.append(iter_toc - iter_tic)\n",
    "                    real_T_list.append(t)\n",
    "                    early_term_count += 1\n",
    "\n",
    "                    if print_option:\n",
    "                        print(\"=============================================\")\n",
    "                        if bisection_count == 11:\n",
    "                            print(\"%s-th bisection iteration terminated early!!\" % bisection_count)\n",
    "                        elif bisection_count == 12:\n",
    "                            print(\"%s-th bisection iteration terminated early!!\" % bisection_count)\n",
    "                        elif bisection_count == 13:\n",
    "                            print(\"%s-th bisection iteration terminated early!!\" % bisection_count)\n",
    "                        elif bisection_count % 10 == 1:\n",
    "                            print(\"%s-st bisection iteration terminated early!!\" % bisection_count)\n",
    "                        elif bisection_count % 10 == 2:\n",
    "                            print(\"%s-nd bisection iteration terminated early!!\" % bisection_count)\n",
    "                        elif bisection_count % 10 == 3:\n",
    "                            print(\"%s-rd bisection iteration terminated early!!\" % bisection_count)\n",
    "                        else:\n",
    "                            print(\"%s-th bisection iteration terminated early!!\" % bisection_count)\n",
    "                        print(\"Terminated in %s iterations\" % (t + 1))\n",
    "                        print(\"Max iteration %s\" % T)\n",
    "                        print('x_bar:', x_ws/ss_sum_x)\n",
    "                        # print('p_bar:', p_bar)\n",
    "                        print('Duality Gap:', diff)\n",
    "                        print(\"=============================================\")\n",
    "                    if pi_val(x_ws/ss_sum_x, p_ws/ss_sum_p, emp_dist_value_copy, RHS) > obj_tol / 2:\n",
    "                        if min_flag:\n",
    "                            opt_low = obj_val\n",
    "                            bisection.append('low')\n",
    "                        else:\n",
    "                            opt_up = obj_val\n",
    "                            bisection.append('up')\n",
    "                    else:\n",
    "                        if min_flag:\n",
    "                            opt_up = obj_val\n",
    "                            bisection.append('up')\n",
    "                        else:\n",
    "                            opt_low = obj_val\n",
    "                            bisection.append('low')\n",
    "\n",
    "                    break\n",
    "\n",
    "                \"\"\"\"\n",
    "    \n",
    "                At the very last iteration. Calculate the duality gap to verify our termination condition.\n",
    "                Raise error if dual gap > obj_tol\n",
    "    \n",
    "                \"\"\"\n",
    "\n",
    "                if dual_gap_cal and t == T - 1 and print_option:\n",
    "                    #array option output\n",
    "                    real_t = T\n",
    "                    x_ws, ss_sum_x = bar_calculator_temp(x_ws, x, T+1 - iter_count*dual_gap_freq, \\\n",
    "                                    ss_x_list[iter_count * dual_gap_freq:],ss_sum_x)\n",
    "                    p_ws, ss_sum_p = bar_calculator_temp(p_ws, p, T+1- iter_count*dual_gap_freq,\\\n",
    "                                                    ss_p_list[0][iter_count * dual_gap_freq:], ss_sum_p)\n",
    "                    sup_val = sup_pi(x_ws / ss_sum_x, emp_dist_value_copy, rho, delta, alpha_tol, RHS)\n",
    "                    inf_val = inf_pi(p_ws / ss_sum_p, emp_dist_value_copy, RHS, PWL_model, var_t, var_x, constr_list)\n",
    "                    diff = sup_val - inf_val\n",
    "                    dual_gap.append(diff)\n",
    "\n",
    "\n",
    "                    print(\"%s-st iteration duality gap:\" % (t + 1), diff)\n",
    "                    if diff > obj_tol:\n",
    "                        raise ValueError(\"Dual Gap greater than Obj_Tol.\")\n",
    "                    # print(\"x_bar:\", x_bar)\n",
    "                    # print(\"p_bar[0,0,0,:]:\",p_bar[0,0,0,:])\n",
    "                    # print(\"p_new[0,0,0:]:\", p_new[0,0,:])\n",
    "                    # print(\"X Coeff:\", temp_coeff)\n",
    "                    print(\"sup_val:\", sup_val)\n",
    "                    print(\"inf_val:\", inf_val)\n",
    "                    if K_grad < n:\n",
    "                        print(\"w_sum:\", w_sum)\n",
    "                    else:\n",
    "                        print('w_sum:', np.sum(p[t + 1], axis=1))\n",
    "\n",
    "            if dual_gap_cal == 0:\n",
    "                real_t = T\n",
    "\n",
    "            dual_gap_list.append(dual_gap)\n",
    "            real_T_list.append(real_t)\n",
    "\n",
    "\n",
    "            if break_flag:\n",
    "                continue\n",
    "\n",
    "            #Calculate the last hat_f_val_ws\n",
    "\n",
    "            hat_f_val_ws += np.tensordot(hat_f_val[: T % dual_gap_freq], ss_x_list[iter_count * dual_gap_freq:T], axes=(0, 0))\n",
    "            ss_sum_x = np.sum(ss_x_list[:T])\n",
    "            hat_f_val_ws /= ss_sum_x\n",
    "\n",
    "            if vartheta_flag:\n",
    "                real_f_val_ws += np.tensordot(real_f_val[: T % dual_gap_freq], ss_x_list[iter_count * dual_gap_freq:T],\n",
    "                                             axes=(0, 0))\n",
    "                real_f_val_ws /= ss_sum_x\n",
    "\n",
    "                print(\"==========Vartheta Comparison===========\")\n",
    "                print(\"hat_f_val_ws: %s\" %hat_f_val_ws)\n",
    "                print(\"real_f_val_ws: %s\" %real_f_val_ws)\n",
    "                print(\"difference with real_f_val_ws: %s\" %(hat_f_val_ws - real_f_val_ws))\n",
    "                if (hat_f_val_ws - real_f_val_ws).max() > 1e-3:\n",
    "                    raise ValueError(\"hat_vartheta not approximating well. Increase Sample Size.\")\n",
    "                print(\"==========================================\")\n",
    "            hat_vartheta = hat_f_val_ws.max()\n",
    "            # Now implement Bisection // We are using hat_vartheta. Our threshold value changed.\n",
    "\n",
    "            if hat_vartheta > R_x + C_K * obj_tol:\n",
    "                if min_flag:\n",
    "                    opt_low = obj_val\n",
    "                    bisection.append('low')\n",
    "                else:\n",
    "                    opt_up = obj_val\n",
    "                    bisection.append('up')\n",
    "            else:\n",
    "                if min_flag:\n",
    "                    opt_up = obj_val\n",
    "                    bisection.append('up')\n",
    "                else:\n",
    "                    opt_low = obj_val\n",
    "                    bisection.append('low')\n",
    "\n",
    "        total_toc = time.time()\n",
    "        total_solved_time = total_toc - total_tic\n",
    "        obj_val = (opt_up + opt_low) / 2\n",
    "\n",
    "        print('Out of %s bisection iteration %s terminated early' % (bisection_count, early_term_count))\n",
    "        print('Average iteration:', mean(real_T_list))\n",
    "        print('==========================================')\n",
    "\n",
    "    stat = Statistics(n, m, K, K_grad, ss_type, obj_val, dual_gap_list,\n",
    "                      iter_timer_list, total_solved_time, real_T_list, T, R_x, R_p, i_flag_count)\n",
    "\n",
    "    # Update the last objective value\n",
    "\n",
    "    # obj_val = (-1 + 2*min_flag) * obj_val\n",
    "\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRO_SMD_K_test_iter(x_0, p_0, emp_dist_value, K, K_grad, delta, rho, alpha_tol, opt_low, opt_up, obj_tol,\n",
    "        RHS,ss_type, C_K, dual_gap_option, dual_gap_freq, T_cap, print_option=1, min_flag=1):\n",
    "\n",
    "    emp_dist_value_copy = emp_dist_value.copy()\n",
    "    emp_dist_value_copy[0, :, :, :] = (-1 + 2 * min_flag) * emp_dist_value_copy[0, :, :, :]\n",
    "\n",
    "    m, J, L, n = emp_dist_value.shape  # Parameters\n",
    "\n",
    "    # Calculate coefficients\n",
    "\n",
    "    C_G = 1 + math.sqrt(rho / n)\n",
    "\n",
    "    print('\\n')\n",
    "    print('************************************************************************************')\n",
    "    print('*******************************Problem Description**********************************')\n",
    "    print(' ')\n",
    "    print('Number of constraints: %s, x dimension: %s ,Uncertainty Set Dimension: %s' % (m, J * L, n))\n",
    "    print(' ')\n",
    "    print('*************************************************************************************')\n",
    "    print('*************************************************************************************')\n",
    "\n",
    "    i_flag_count = 0\n",
    "    print('We are doing sample size test here!')\n",
    "\n",
    "    stoc_factor = 1  # We need to adjust this part later Sep-20\n",
    "\n",
    "    # G is bound of norm of gradient(\\nabla) F_k^i(x) for all k \\in [n] and i \\in [m] and x \\in X\n",
    "    G = np.absolute(emp_dist_value).max()  # Also, need to change this funciton add C2\n",
    "    # M is an list of bound of |F_k^i(x)| for each i \\in [m]\n",
    "    absolute_max = np.absolute(emp_dist_value).max(axis=2)\n",
    "    sum_over_J = np.sum(absolute_max, axis=1)\n",
    "    M = sum_over_J.max(axis=1)\n",
    "\n",
    "    # Calculate T and our stepsize\n",
    "    if ss_type == 'constant':\n",
    "        T, R_x, R_p, ss_x, ss_p = R_const_SMD(J, L, n, G, M, delta, rho, obj_tol, C_G, C_K, stoc_factor)\n",
    "        print(\"Max Iteration:\", T_cap)\n",
    "        print('alg_type:SGD with i_hat')\n",
    "        T = T_cap\n",
    "        obj_tol = 1e-7\n",
    "        ss_x_list = ss_x * np.ones(T + 1)\n",
    "        ss_p_list = []\n",
    "        for i in range(m):\n",
    "            ss_p_list.append(ss_p[i] * np.ones(T + 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    elif ss_type == 'diminish':\n",
    "        T, R_x, R_p, c_x, c_p = R_dim_SMD(J, L, n, G, M, delta, rho, obj_tol, C_G, C_K,\n",
    "                                          stoc_factor)\n",
    "        print(\"Max Iteration:\", T_cap)\n",
    "        print('alg_type:SGD with i_hat')\n",
    "        T = T_cap\n",
    "        ss_x_list = c_x * (np.sqrt(1 / (np.arange(T + 1) + 1)))\n",
    "        obj_tol = 1e-7\n",
    "        ss_p_list = []\n",
    "        for i in range(m):\n",
    "            ss_p_list.append(c_p[i] * (np.sqrt(1 / (np.arange(T + 1) + 1))))\n",
    "\n",
    "\n",
    "    print('Rx: %s' %R_x)\n",
    "    print('Rp: %s' %R_p)\n",
    "\n",
    "    # This String List would be used on inf_pi function\n",
    "    constr_list = []\n",
    "    for i in range(m):\n",
    "        constr_list.append('obj_' + str(i))\n",
    "\n",
    "    bisection = []\n",
    "    bisection_count = 0\n",
    "\n",
    "    vartheta_list = []\n",
    "\n",
    "    # x_coeff,_ = get_coeff(emp_dist_value_copy,rho,delta, alpha_tol)\n",
    "    # print(x_coeff)\n",
    "    # Define a PWL to calculate inf_pi\n",
    "    list_J = list(range(J))\n",
    "    list_L = list(range(L))\n",
    "\n",
    "    PWL_model = gp.Model('PWL')\n",
    "\n",
    "    PWL_model.setParam('OutputFlag', 0)\n",
    "    var_t = PWL_model.addVar(lb=-GRB.INFINITY, name='t')\n",
    "    var_x = PWL_model.addVars(list_J, list_L, ub=1, name='x')\n",
    "    PWL_model.addConstrs(gp.quicksum(var_x[j, l] for l in list_L) == 1 for j in list_J)\n",
    "\n",
    "    # Create dummy constraints\n",
    "    for i in range(m):\n",
    "        PWL_model.addConstr(var_t >= i, name=constr_list[i])\n",
    "\n",
    "    obj = var_t\n",
    "\n",
    "    PWL_model.setObjective(obj, GRB.MINIMIZE)\n",
    "    PWL_model.optimize()\n",
    "\n",
    "    dual_gap_list = []  # each element is a list of dual gap at each bisection iteration\n",
    "    iter_timer_list = []  # each element  elapsed time per bisection\n",
    "    real_T_list = []  # each element is a list of terminated iteration by dual gap condition at each\n",
    "    # bisection iteration\n",
    "    early_term_count = 0\n",
    "\n",
    "    total_tic = time.time()\n",
    "\n",
    "    sample_freq = 10 ** 5  # We can move this to parameter.\n",
    "    sanity_check = 0\n",
    "    sanity_freq = 1000\n",
    "\n",
    "    if dual_gap_option == 2 or dual_gap_option == 0:\n",
    "        pass\n",
    "    elif dual_gap_option == 3 or dual_gap_option == 1:\n",
    "        dual_gap_freq = int(T * dual_gap_freq)\n",
    "\n",
    "    # Set calculation option\n",
    "    if dual_gap_option == 0 or dual_gap_option == 1:\n",
    "        dual_gap_cal = 0\n",
    "    else:\n",
    "        dual_gap_cal = 1\n",
    "\n",
    "\n",
    "    bisection_count += 1\n",
    "    # Change our objective function\n",
    "    obj_val = (opt_up + opt_low) / 2\n",
    "    RHS[0] = (-1 + 2 * min_flag) * obj_val\n",
    "    if print_option:\n",
    "        print('---------------------------')\n",
    "        print('%s-th bisection iteration' % bisection_count)\n",
    "        print('alg_type:SGD with i_hat')\n",
    "        print('---------------------------')\n",
    "        print(\"current step objective value:\", obj_val)\n",
    "\n",
    "    x = np.empty([dual_gap_freq, J, L])\n",
    "    x[0, :, :] = x_0\n",
    "    p = np.empty([dual_gap_freq, m, n])\n",
    "    p[0, :, :] = p_0\n",
    "\n",
    "    hat_f_val = np.zeros([dual_gap_freq, m])\n",
    "    hat_f_val_ws = np.zeros(m)\n",
    "\n",
    "    # Variables that is needed to update periodically.\n",
    "    iter_count = 0\n",
    "    ss_sum_x = 0\n",
    "    ss_sum_p = 0  # This does not have to be np.zeros([m])\n",
    "    x_ws = np.zeros([J, L])\n",
    "    p_ws = np.zeros([m, n])\n",
    "\n",
    "    # Get x and p for T iterations\n",
    "    tic = time.time()\n",
    "\n",
    "    w_sum = np.zeros(m)\n",
    "    w_sum[:] = np.nan\n",
    "    w_square_sum = np.zeros(m)\n",
    "    w_square_sum[:] = np.nan\n",
    "    cum_dist = np.zeros([m, n])\n",
    "    cum_dist[:] = np.nan\n",
    "\n",
    "    for i in range(m):\n",
    "        w_sum[i] = np.sum(p_0[i, :])\n",
    "        w_square_sum[i] = np.sum(p_0[i, :] ** 2)\n",
    "        cum_dist[i, :] = np.cumsum(p_0[i, :])\n",
    "\n",
    "    dual_gap = []  # List that contains duality gap in this bisection\n",
    "\n",
    "    sup_val = sup_pi(x_0, emp_dist_value_copy, rho, delta, alpha_tol, RHS)\n",
    "    inf_val = inf_pi(p_0, emp_dist_value_copy, RHS, PWL_model, var_t, var_x, constr_list)\n",
    "    diff = sup_val - inf_val\n",
    "    dual_gap.append(diff)\n",
    "\n",
    "    for t in range(T):\n",
    "\n",
    "        # Now our step-size is not uniform. Make sure to change x_bar and p_bar according to our step size\n",
    "        # Create samples\n",
    "        if t % sample_freq == 0:\n",
    "            temp_samples_list = np.random.rand(m, K, sample_freq)\n",
    "            grad_samples_list = np.random.rand(K_grad, sample_freq)\n",
    "\n",
    "        if print_option and (t + 2) % dual_gap_freq == 0:\n",
    "            toc = time.time()\n",
    "            print('=========================================')\n",
    "            print('%s-st iteration start time:' % (t + 1), toc - tic)\n",
    "        # We do not need information of p_t here. Only cumdist and w_sum is needed.\n",
    "        x[(t + 1) % dual_gap_freq, :, :], hat_f_val[t % dual_gap_freq, :], i_hat_flag = SMD_x_K_test(K, K_grad,\n",
    "                x[t % dual_gap_freq, :, :],p[t%dual_gap_freq,:,:] ,ss_x_list[t],temp_samples_list[:, :, t % sample_freq],\n",
    "                       grad_samples_list[:,t % sample_freq], RHS, emp_dist_value_copy, w_sum, cum_dist)\n",
    "        i_flag_count += i_hat_flag\n",
    "\n",
    "        for i in range(m):\n",
    "            p[(t + 1) % dual_gap_freq, i, :], w_sum[i], w_square_sum[i], cum_dist[i, :] = \\\n",
    "                SMD_p(x[t % dual_gap_freq, :, :], p[t % dual_gap_freq, i, :], i, ss_p_list[i][t], delta, rho,\n",
    "                      alpha_tol, \\\n",
    "                      emp_dist_value_copy, w_sum[i], w_square_sum[i], cum_dist[i, :])\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Calculate Duality Gap\n",
    "\n",
    "        \"\"\"\n",
    "        # Calculate Dual gap\n",
    "        if dual_gap_cal and (t + 2) % dual_gap_freq == 0:\n",
    "            x_ws, ss_sum_x = bar_calculator_temp(x_ws, x, dual_gap_freq, \\\n",
    "                                                 ss_x_list[\n",
    "                                                 iter_count * dual_gap_freq:(iter_count + 1) * dual_gap_freq],\n",
    "                                                 ss_sum_x)\n",
    "            p_ws, ss_sum_p = bar_calculator_temp(p_ws, p, dual_gap_freq, \\\n",
    "                                                 ss_p_list[0][\n",
    "                                                 iter_count * dual_gap_freq:(iter_count + 1) * dual_gap_freq],\n",
    "                                                 ss_sum_p)\n",
    "            sup_val = sup_pi(x_ws / ss_sum_x, emp_dist_value_copy, rho, delta, alpha_tol, RHS)\n",
    "            inf_val = inf_pi(p_ws / ss_sum_p, emp_dist_value_copy, RHS, PWL_model, var_t, var_x, constr_list)\n",
    "            diff = sup_val - inf_val\n",
    "            dual_gap.append(diff)\n",
    "\n",
    "        if dual_gap_cal and (t + 2) % dual_gap_freq == 0 and print_option:\n",
    "            print(\"%s-st iteration duality gap:\" % (t + 1), diff)\n",
    "            # print(\"x_bar:\", x_bar)\n",
    "            # print(\"p_bar[0,0,0,:]:\",p_bar[0,0,0,:])\n",
    "            # print(\"p_new[0,0,0:]:\", p_new[0,0,:])\n",
    "            # print(\"X Coeff:\", temp_coeff)\n",
    "            print(\"sup_val:\", sup_val)\n",
    "            print(\"inf_val:\", inf_val)\n",
    "            if K_grad < n:\n",
    "                print(\"w_sum:\", w_sum)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Update hat_f_val_ws every dual_gap_freq iteration.\n",
    "\n",
    "        \"\"\"\n",
    "        # Whether dual_gap_cal ==0 or not, we calculate hat_f_val_ws. Also, this update comes later than dual\n",
    "        # gap calculation, so we increase our iter_count here.\n",
    "        if (t + 1) % dual_gap_freq == 0:\n",
    "            hat_f_val_ws += np.tensordot(hat_f_val, ss_x_list[iter_count * dual_gap_freq: \\\n",
    "                                                              (iter_count + 1) * dual_gap_freq], axes=(0, 0))\n",
    "            iter_count += 1\n",
    "\n",
    "    dual_gap_list.append(dual_gap)\n",
    "    total_toc = time.time()\n",
    "    total_solved_time = total_toc - total_tic\n",
    "\n",
    "    SMD_stat = Statistics(n, m, K, K_grad, ss_type, obj_val, dual_gap_list,\n",
    "                      iter_timer_list, total_solved_time, real_T_list, T, R_x, R_p, i_flag_count)\n",
    "\n",
    "    return SMD_stat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
